{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjoXjjOj2Kaq"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1625209091967,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "eMvQwUpC2CyT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.backends.cudnn.benchmark=True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.manual_seed(5703)\n",
    "torch.manual_seed(5703)\n",
    "np.random.seed(5703)\n",
    "random.seed(5703)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google-colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "id = '1rxgk3e9O4doAoEFN3BeZqKULqGl7j6yV'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('Device #1.csv')   # Device #1\n",
    "\n",
    "id = '1YXc02xvqULO0uUP7xcb4W84SV6RxruoN'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('Device #2.csv')   # Device #2\n",
    "\n",
    "id = '1NZL4v46VhdSKmF2NKAYdWIQ0yGmh4Aic'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('Device #3.csv')   # Device #3\n",
    "\n",
    "id = '1izH8XwPLYgvy6h1BLM8gwCqVntgwYsvq'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('Device #4.csv')   # Device #4\n",
    "\n",
    "id = '115ev199YrX-Jqf0TbbibebABPKPxtffg'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('Device #5.csv')   # Device #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68492,
     "status": "ok",
     "timestamp": 1625208934673,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "hsKSt5lF2Cou",
    "outputId": "acd812d5-2bde-45e7-d90c-e11d97ab58c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1018298, 117),\n",
       " (835876, 117),\n",
       " (355500, 117),\n",
       " (1098677, 117),\n",
       " (828260, 117),\n",
       " (836891, 117),\n",
       " (375222, 117),\n",
       " (863056, 117),\n",
       " (414622, 117))"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "d1 = pd.read_csv('/content/Device #1.csv')\n",
    "d2 = pd.read_csv('/content/Device #2.csv')\n",
    "d3 = pd.read_csv('/content/Device #3.csv')\n",
    "d4 = pd.read_csv('/content/Device #4.csv')\n",
    "d5 = pd.read_csv('/content/Device #5.csv')\n",
    "d1.shape, d2.shape, d3.shape, d4.shape, d5.shape, d6.shape, d7.shape, d8.shape, d9.shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>17.677670</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142377</td>\n",
       "      <td>46</td>\n",
       "      <td>62</td>\n",
       "      <td>1325</td>\n",
       "      <td>105855</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>28.804348</td>\n",
       "      <td>111.407285</td>\n",
       "      <td>4344</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118873</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>1169</td>\n",
       "      <td>45025</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>50.826087</td>\n",
       "      <td>156.137367</td>\n",
       "      <td>2896</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143577</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "      <td>1301</td>\n",
       "      <td>107289</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>30.255814</td>\n",
       "      <td>115.178969</td>\n",
       "      <td>4344</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143745</td>\n",
       "      <td>49</td>\n",
       "      <td>59</td>\n",
       "      <td>1331</td>\n",
       "      <td>110185</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>27.163265</td>\n",
       "      <td>108.067176</td>\n",
       "      <td>4344</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0              4                  2                       0   \n",
       "1         142377                 46                      62   \n",
       "2         118873                 23                      28   \n",
       "3         143577                 43                      55   \n",
       "4         143745                 49                      59   \n",
       "\n",
       "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                           37                            0   \n",
       "1                         1325                       105855   \n",
       "2                         1169                        45025   \n",
       "3                         1301                       107289   \n",
       "4                         1331                       110185   \n",
       "\n",
       "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                     31                      6               18.500000   \n",
       "1                    570                      0               28.804348   \n",
       "2                    570                      0               50.826087   \n",
       "3                    570                      0               30.255814   \n",
       "4                    570                      0               27.163265   \n",
       "\n",
       "   Fwd Packet Length Std  Bwd Packet Length Max  ...  min_seg_size_forward  \\\n",
       "0              17.677670                      0  ...                    20   \n",
       "1             111.407285                   4344  ...                    20   \n",
       "2             156.137367                   2896  ...                    32   \n",
       "3             115.178969                   4344  ...                    20   \n",
       "4             108.067176                   4344  ...                    20   \n",
       "\n",
       "   Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n",
       "0          0.0         0.0           0           0        0.0       0.0   \n",
       "1          0.0         0.0           0           0        0.0       0.0   \n",
       "2          0.0         0.0           0           0        0.0       0.0   \n",
       "3          0.0         0.0           0           0        0.0       0.0   \n",
       "4          0.0         0.0           0           0        0.0       0.0   \n",
       "\n",
       "   Idle Max  Idle Min   Label  \n",
       "0         0         0  BENIGN  \n",
       "1         0         0  BENIGN  \n",
       "2         0         0  BENIGN  \n",
       "3         0         0  BENIGN  \n",
       "4         0         0  BENIGN  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read dataset\n",
    "df = pd.read_csv('https://tinyurl.com/vrv62fzc') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN          22731\n",
       "DoS             19035\n",
       "PortScan         7946\n",
       "BruteForce       2767\n",
       "WebAttack        2180\n",
       "Bot              1966\n",
       "Infiltration       36\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization\n",
    "features = df.dtypes[df.dtypes != 'object'].index\n",
    "df[features] = df[features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# Fill empty values by 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22731\n",
       "3    19035\n",
       "5     7946\n",
       "2     2767\n",
       "6     2180\n",
       "1     1966\n",
       "4       36\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])\n",
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>klabel</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.528470</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.081806</td>\n",
       "      <td>-0.032573</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.202326</td>\n",
       "      <td>-0.085798</td>\n",
       "      <td>-0.141625</td>\n",
       "      <td>-0.176448</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.524593</td>\n",
       "      <td>0.704878</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.027749</td>\n",
       "      <td>0.920410</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.082434</td>\n",
       "      <td>0.240596</td>\n",
       "      <td>1.006302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.525233</td>\n",
       "      <td>0.300651</td>\n",
       "      <td>0.339163</td>\n",
       "      <td>0.020443</td>\n",
       "      <td>0.363712</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>0.044064</td>\n",
       "      <td>0.439619</td>\n",
       "      <td>0.484295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.524560</td>\n",
       "      <td>0.652153</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.026625</td>\n",
       "      <td>0.933533</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.074097</td>\n",
       "      <td>0.257378</td>\n",
       "      <td>1.006302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.524555</td>\n",
       "      <td>0.757604</td>\n",
       "      <td>0.805237</td>\n",
       "      <td>0.028030</td>\n",
       "      <td>0.960037</td>\n",
       "      <td>0.603275</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.091861</td>\n",
       "      <td>0.225734</td>\n",
       "      <td>1.006302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56656</th>\n",
       "      <td>-0.528463</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.051737</td>\n",
       "      <td>-0.031309</td>\n",
       "      <td>-0.046220</td>\n",
       "      <td>-0.200831</td>\n",
       "      <td>0.457498</td>\n",
       "      <td>-0.064078</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.517901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56657</th>\n",
       "      <td>-0.524840</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.051737</td>\n",
       "      <td>-0.029904</td>\n",
       "      <td>-0.043932</td>\n",
       "      <td>-0.178412</td>\n",
       "      <td>0.770939</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.472838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56658</th>\n",
       "      <td>-0.215111</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>-0.021667</td>\n",
       "      <td>-0.013231</td>\n",
       "      <td>-0.016083</td>\n",
       "      <td>0.423920</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>0.269089</td>\n",
       "      <td>0.640328</td>\n",
       "      <td>0.711051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108682</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.127669</td>\n",
       "      <td>-0.093554</td>\n",
       "      <td>-0.256386</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.269448</td>\n",
       "      <td>-0.238252</td>\n",
       "      <td>352</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56659</th>\n",
       "      <td>-0.215111</td>\n",
       "      <td>0.037025</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>-0.014823</td>\n",
       "      <td>0.058109</td>\n",
       "      <td>0.373103</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>0.050807</td>\n",
       "      <td>0.399311</td>\n",
       "      <td>1.528310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108677</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.127664</td>\n",
       "      <td>-0.093548</td>\n",
       "      <td>-0.256402</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.269464</td>\n",
       "      <td>-0.238268</td>\n",
       "      <td>980</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56660</th>\n",
       "      <td>-0.214989</td>\n",
       "      <td>0.037025</td>\n",
       "      <td>-0.006633</td>\n",
       "      <td>-0.019038</td>\n",
       "      <td>0.058109</td>\n",
       "      <td>0.238587</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.013815</td>\n",
       "      <td>0.257731</td>\n",
       "      <td>3.111635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108683</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.127670</td>\n",
       "      <td>-0.093555</td>\n",
       "      <td>-0.256275</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.269340</td>\n",
       "      <td>-0.238140</td>\n",
       "      <td>328</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52479 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0          -0.528470          -0.068426               -0.081806   \n",
       "1          -0.524593           0.704878                0.850340   \n",
       "2          -0.525233           0.300651                0.339163   \n",
       "3          -0.524560           0.652153                0.745098   \n",
       "4          -0.524555           0.757604                0.805237   \n",
       "...              ...                ...                     ...   \n",
       "56656      -0.528463          -0.068426               -0.051737   \n",
       "56657      -0.524840          -0.068426               -0.051737   \n",
       "56658      -0.215111          -0.015701               -0.021667   \n",
       "56659      -0.215111           0.037025                0.008402   \n",
       "56660      -0.214989           0.037025               -0.006633   \n",
       "\n",
       "       Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                        -0.032573                    -0.048343   \n",
       "1                         0.027749                     0.920410   \n",
       "2                         0.020443                     0.363712   \n",
       "3                         0.026625                     0.933533   \n",
       "4                         0.028030                     0.960037   \n",
       "...                            ...                          ...   \n",
       "56656                    -0.031309                    -0.046220   \n",
       "56657                    -0.029904                    -0.043932   \n",
       "56658                    -0.013231                    -0.016083   \n",
       "56659                    -0.014823                     0.058109   \n",
       "56660                    -0.019038                     0.058109   \n",
       "\n",
       "       Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                  -0.202326              -0.085798               -0.141625   \n",
       "1                   0.603275              -0.211174               -0.082434   \n",
       "2                   0.603275              -0.211174                0.044064   \n",
       "3                   0.603275              -0.211174               -0.074097   \n",
       "4                   0.603275              -0.211174               -0.091861   \n",
       "...                      ...                    ...                     ...   \n",
       "56656              -0.200831               0.457498               -0.064078   \n",
       "56657              -0.178412               0.770939                0.022086   \n",
       "56658               0.423920              -0.211174                0.269089   \n",
       "56659               0.373103              -0.211174                0.050807   \n",
       "56660               0.238587              -0.211174               -0.013815   \n",
       "\n",
       "       Fwd Packet Length Std  Bwd Packet Length Max  ...  Active Mean  \\\n",
       "0                  -0.176448              -0.559719  ...    -0.109889   \n",
       "1                   0.240596               1.006302  ...    -0.109889   \n",
       "2                   0.439619               0.484295  ...    -0.109889   \n",
       "3                   0.257378               1.006302  ...    -0.109889   \n",
       "4                   0.225734               1.006302  ...    -0.109889   \n",
       "...                      ...                    ...  ...          ...   \n",
       "56656              -0.255104              -0.517901  ...    -0.109889   \n",
       "56657              -0.255104              -0.472838  ...    -0.109889   \n",
       "56658               0.640328               0.711051  ...    -0.108682   \n",
       "56659               0.399311               1.528310  ...    -0.108677   \n",
       "56660               0.257731               3.111635  ...    -0.108683   \n",
       "\n",
       "       Active Std  Active Max  Active Min  Idle Mean  Idle Std  Idle Max  \\\n",
       "0       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "1       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "2       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "3       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "4       -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "...           ...         ...         ...        ...       ...       ...   \n",
       "56656   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "56657   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "56658   -0.081786   -0.127669   -0.093554  -0.256386 -0.137651 -0.269448   \n",
       "56659   -0.081786   -0.127664   -0.093548  -0.256402 -0.137651 -0.269464   \n",
       "56660   -0.081786   -0.127670   -0.093555  -0.256275 -0.137651 -0.269340   \n",
       "\n",
       "       Idle Min  klabel  Label  \n",
       "0     -0.442057     133      0  \n",
       "1     -0.442057     410      0  \n",
       "2     -0.442057     682      0  \n",
       "3     -0.442057     410      0  \n",
       "4     -0.442057     410      0  \n",
       "...         ...     ...    ...  \n",
       "56656 -0.442057     851      0  \n",
       "56657 -0.442057     976      0  \n",
       "56658 -0.238252     352      3  \n",
       "56659 -0.238268     980      3  \n",
       "56660 -0.238140     328      3  \n",
       "\n",
       "[52479 rows x 79 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain the minority class instances and sample the majority class instances\n",
    "df_minor = df[(df['Label']==6)|(df['Label']==1)|(df['Label']==4)]\n",
    "df_major = df.drop(df_minor.index)\n",
    "\n",
    "X = df_major.drop(['Label'],axis=1) \n",
    "y = df_major.iloc[:, -1].values.reshape(-1,1)\n",
    "y=np.ravel(y)\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "kmeans = MiniBatchKMeans(n_clusters=1000, random_state=0).fit(X)\n",
    "\n",
    "klabel=kmeans.labels_\n",
    "df_major['klabel']=klabel\n",
    "\n",
    "df_major['klabel'].value_counts()\n",
    "\n",
    "cols = list(df_major)\n",
    "cols.insert(78, cols.pop(cols.index('Label')))\n",
    "df_major = df_major.loc[:, cols]\n",
    "\n",
    "df_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    114\n",
       "3    105\n",
       "5     60\n",
       "2     22\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def typicalSampling(group):\n",
    "    name = group.name\n",
    "    frac = 0.008\n",
    "    return group.sample(frac=frac)\n",
    "\n",
    "result = df_major.groupby(\n",
    "    'klabel', group_keys=False\n",
    ").apply(typicalSampling)\n",
    "\n",
    "result['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>klabel</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>-0.421157</td>\n",
       "      <td>-0.033276</td>\n",
       "      <td>-0.081806</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.239691</td>\n",
       "      <td>-0.085798</td>\n",
       "      <td>-0.213428</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25182</th>\n",
       "      <td>-0.528464</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.051737</td>\n",
       "      <td>-0.030278</td>\n",
       "      <td>-0.046531</td>\n",
       "      <td>-0.184390</td>\n",
       "      <td>0.687355</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.524030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>-0.507000</td>\n",
       "      <td>-0.050851</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>-0.033088</td>\n",
       "      <td>0.057826</td>\n",
       "      <td>-0.218767</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.198110</td>\n",
       "      <td>-0.209439</td>\n",
       "      <td>1.019281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>-0.508440</td>\n",
       "      <td>-0.050851</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>-0.033088</td>\n",
       "      <td>0.057826</td>\n",
       "      <td>-0.218767</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.198110</td>\n",
       "      <td>-0.209439</td>\n",
       "      <td>1.019281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12205</th>\n",
       "      <td>-0.528468</td>\n",
       "      <td>-0.086001</td>\n",
       "      <td>-0.066771</td>\n",
       "      <td>-0.034306</td>\n",
       "      <td>-0.048288</td>\n",
       "      <td>-0.248659</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.247894</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.557556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52463</th>\n",
       "      <td>-0.528442</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>-0.081806</td>\n",
       "      <td>-0.034306</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.248659</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.247894</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>983</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44504</th>\n",
       "      <td>2.183831</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>-0.006633</td>\n",
       "      <td>-0.018336</td>\n",
       "      <td>0.057771</td>\n",
       "      <td>0.261006</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.364314</td>\n",
       "      <td>3.094331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108543</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.127559</td>\n",
       "      <td>-0.093403</td>\n",
       "      <td>2.636937</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>2.547366</td>\n",
       "      <td>2.675989</td>\n",
       "      <td>984</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31937</th>\n",
       "      <td>-0.527820</td>\n",
       "      <td>-0.086001</td>\n",
       "      <td>-0.066771</td>\n",
       "      <td>-0.032105</td>\n",
       "      <td>-0.047657</td>\n",
       "      <td>-0.178412</td>\n",
       "      <td>0.770939</td>\n",
       "      <td>0.022086</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.532682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53350</th>\n",
       "      <td>-0.525891</td>\n",
       "      <td>-0.086001</td>\n",
       "      <td>-0.066771</td>\n",
       "      <td>-0.032011</td>\n",
       "      <td>-0.047318</td>\n",
       "      <td>-0.175423</td>\n",
       "      <td>0.812731</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.519343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48646</th>\n",
       "      <td>-0.528470</td>\n",
       "      <td>-0.068426</td>\n",
       "      <td>-0.081806</td>\n",
       "      <td>-0.034306</td>\n",
       "      <td>-0.048343</td>\n",
       "      <td>-0.248659</td>\n",
       "      <td>-0.211174</td>\n",
       "      <td>-0.247894</td>\n",
       "      <td>-0.255104</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109889</td>\n",
       "      <td>-0.081786</td>\n",
       "      <td>-0.128620</td>\n",
       "      <td>-0.094860</td>\n",
       "      <td>-0.458729</td>\n",
       "      <td>-0.137651</td>\n",
       "      <td>-0.466440</td>\n",
       "      <td>-0.442057</td>\n",
       "      <td>995</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "5635       -0.421157          -0.033276               -0.081806   \n",
       "25182      -0.528464          -0.068426               -0.051737   \n",
       "745        -0.507000          -0.050851                0.008402   \n",
       "1501       -0.508440          -0.050851                0.008402   \n",
       "12205      -0.528468          -0.086001               -0.066771   \n",
       "...              ...                ...                     ...   \n",
       "52463      -0.528442          -0.015701               -0.081806   \n",
       "44504       2.183831           0.001874               -0.006633   \n",
       "31937      -0.527820          -0.086001               -0.066771   \n",
       "53350      -0.525891          -0.086001               -0.066771   \n",
       "48646      -0.528470          -0.068426               -0.081806   \n",
       "\n",
       "       Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "5635                     -0.033182                    -0.048343   \n",
       "25182                    -0.030278                    -0.046531   \n",
       "745                      -0.033088                     0.057826   \n",
       "1501                     -0.033088                     0.057826   \n",
       "12205                    -0.034306                    -0.048288   \n",
       "...                            ...                          ...   \n",
       "52463                    -0.034306                    -0.048343   \n",
       "44504                    -0.018336                     0.057771   \n",
       "31937                    -0.032105                    -0.047657   \n",
       "53350                    -0.032011                    -0.047318   \n",
       "48646                    -0.034306                    -0.048343   \n",
       "\n",
       "       Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "5635               -0.239691              -0.085798               -0.213428   \n",
       "25182              -0.184390               0.687355               -0.000891   \n",
       "745                -0.218767              -0.211174               -0.198110   \n",
       "1501               -0.218767              -0.211174               -0.198110   \n",
       "12205              -0.248659              -0.211174               -0.247894   \n",
       "...                      ...                    ...                     ...   \n",
       "52463              -0.248659              -0.211174               -0.247894   \n",
       "44504               0.261006              -0.211174                0.078571   \n",
       "31937              -0.178412               0.770939                0.022086   \n",
       "53350              -0.175423               0.812731                0.033575   \n",
       "48646              -0.248659              -0.211174               -0.247894   \n",
       "\n",
       "       Fwd Packet Length Std  Bwd Packet Length Max  ...  Active Mean  \\\n",
       "5635               -0.255104              -0.559719  ...    -0.109889   \n",
       "25182              -0.255104              -0.524030  ...    -0.109889   \n",
       "745                -0.209439               1.019281  ...    -0.109889   \n",
       "1501               -0.209439               1.019281  ...    -0.109889   \n",
       "12205              -0.255104              -0.557556  ...    -0.109889   \n",
       "...                      ...                    ...  ...          ...   \n",
       "52463              -0.255104              -0.559719  ...    -0.109889   \n",
       "44504               0.364314               3.094331  ...    -0.108543   \n",
       "31937              -0.255104              -0.532682  ...    -0.109889   \n",
       "53350              -0.255104              -0.519343  ...    -0.109889   \n",
       "48646              -0.255104              -0.559719  ...    -0.109889   \n",
       "\n",
       "       Active Std  Active Max  Active Min  Idle Mean  Idle Std  Idle Max  \\\n",
       "5635    -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "25182   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "745     -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "1501    -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "12205   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "...           ...         ...         ...        ...       ...       ...   \n",
       "52463   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "44504   -0.081786   -0.127559   -0.093403   2.636937 -0.137651  2.547366   \n",
       "31937   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "53350   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "48646   -0.081786   -0.128620   -0.094860  -0.458729 -0.137651 -0.466440   \n",
       "\n",
       "       Idle Min  klabel  Label  \n",
       "5635  -0.442057       2      3  \n",
       "25182 -0.442057       9      0  \n",
       "745   -0.442057      10      3  \n",
       "1501  -0.442057      10      3  \n",
       "12205 -0.442057      13      5  \n",
       "...         ...     ...    ...  \n",
       "52463 -0.442057     983      3  \n",
       "44504  2.675989     984      3  \n",
       "31937 -0.442057     987      0  \n",
       "53350 -0.442057     989      0  \n",
       "48646 -0.442057     995      3  \n",
       "\n",
       "[301 rows x 79 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LM8FgkcQ4uBb"
   },
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1625208934674,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "jaQOpkU12Chi"
   },
   "outputs": [],
   "source": [
    "def pre_processing(data):\n",
    "    data = data.drop(data.columns[0], axis=1)\n",
    "\n",
    "    benign = data[data['type'] == 'benign'] \n",
    "    benign = benign.drop('type',1)\n",
    "    benign['type'] = 0\n",
    "\n",
    "    abnormal = data[data['type'] != 'benign']\n",
    "    abnormal = abnormal.drop('type',1)\n",
    "    abnormal['type'] = 1\n",
    "\n",
    "    # split benign data evenly to three parts\n",
    "    benign_train, benign_tr, benign_test = np.split(benign, [int((1/3)*len(benign)), int((2/3)*len(benign))])\n",
    "    benign_test_mix = benign_test.copy()    # with label 116\n",
    "\n",
    "    train_label = benign_train['type']\n",
    "\n",
    "    benign_train = benign_train.drop('type',axis=1)\n",
    "    benign_tr = benign_tr.drop('type',axis=1)\n",
    "\n",
    "    # Create Mix data\n",
    "    abnormal_sample = abnormal.sample(frac = 1)             \n",
    "    mix_temp = pd.concat([benign_test_mix, abnormal_sample]) \n",
    "    mix_temp = shuffle(mix_temp, random_state=1)  \n",
    "\n",
    "    mix = mix_temp.copy()                  \n",
    "    mix_data = mix_temp.drop('type',axis=1) \n",
    "    mix_label = mix['type']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    benign_train = scaler.fit_transform(benign_train) \n",
    "    benign_tr = scaler.transform(benign_tr)          \n",
    "    mix_data = scaler.transform(mix_data)            \n",
    "\n",
    "    # keep benign_train as original form here --> for later use\n",
    "    benign_tr = torch.from_numpy(np.array(benign_tr)).float().to(device)  \n",
    "    mix_data = torch.from_numpy(np.array(mix_data)).float().to(device)    \n",
    "    mix_label = torch.tensor(np.array(mix_label))\n",
    "\n",
    "    return benign_train, benign_tr, mix_data, mix_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1625208934676,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "Luz9BSZR2Ccp"
   },
   "outputs": [],
   "source": [
    "def other_pre_processing(data):\n",
    "    data = data.drop(data.columns[0], axis=1)\n",
    "\n",
    "    benign = data[data['type'] == 'benign'] \n",
    "    benign = benign.drop('type',1)\n",
    "    benign['type'] = 0\n",
    "\n",
    "    abnormal = data[data['type'] != 'benign']\n",
    "    abnormal = abnormal.drop('type',1)\n",
    "    abnormal['type'] = 1\n",
    "\n",
    "    # split benign data to two parts\n",
    "    benign_tr, benign_test = train_test_split(benign, test_size = 0.2, random_state = 5703)\n",
    "    benign_tr = benign_tr.drop('type',axis=1)\n",
    "\n",
    "    # Create Mix data\n",
    "    abnormal_sample = abnormal.sample(frac = 1)           \n",
    "    mix_temp = pd.concat([benign_test, abnormal_sample])  \n",
    "    mix_temp = shuffle(mix_temp, random_state=1)         \n",
    "\n",
    "    mix = mix_temp.copy()                   \n",
    "    mix_data = mix_temp.drop('type',axis=1) \n",
    "    mix_label = mix['type']\n",
    "\n",
    "    # Standardisation\n",
    "    scaler = StandardScaler()\n",
    "    benign_tr = scaler.fit_transform(benign_tr)        \n",
    "    mix_data = scaler.transform(mix_data) \n",
    "\n",
    "    benign_tr = torch.from_numpy(np.array(benign_tr)).float().to(device)  \n",
    "    mix_data = torch.from_numpy(np.array(mix_data)).float().to(device)   \n",
    "    mix_label = torch.tensor(np.array(mix_label))                       \n",
    "\n",
    "    return benign_tr, mix_data, mix_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 22967,
     "status": "ok",
     "timestamp": 1625208957634,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "fhbXII4L2CZF"
   },
   "outputs": [],
   "source": [
    "# for Federated Model training\n",
    "benign_train_1, benign_tr_1, mix_data_1, mix_label_1 = pre_processing(d1)\n",
    "benign_train_2, benign_tr_2, mix_data_2, mix_label_2 = pre_processing(d2)\n",
    "benign_train_3, benign_tr_3, mix_data_3, mix_label_3 = pre_processing(d3)\n",
    "benign_train_4, benign_tr_4, mix_data_4, mix_label_4 = pre_processing(d4)\n",
    "benign_train_5, benign_tr_5, mix_data_5, mix_label_5 = pre_processing(d5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM approach for client dataset modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "# Define the input shape for the model\n",
    "input_shape = (None, 10, 1)\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(64, input_shape=input_shape[1:], return_sequences=True),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the TFF type representing a single client's data\n",
    "input_type = tff.TensorType(tf.float32, shape=input_shape)\n",
    "\n",
    "# Define the TFF type representing a batch of client data\n",
    "batch_type = tff.NamedTupleType([('x', input_type), ('y', input_type)])\n",
    "\n",
    "# Define the loss function for the model\n",
    "def loss(model, batch):\n",
    "    y_pred = model(batch.x)\n",
    "    return tf.keras.losses.binary_crossentropy(batch.y, y_pred)\n",
    "\n",
    "# Define the evaluation metric for the model\n",
    "def accuracy(model, batch):\n",
    "    y_pred = model(batch.x)\n",
    "    return tf.keras.metrics.binary_accuracy(batch.y, y_pred)\n",
    "\n",
    "# Define the TFF type representing a federated dataset\n",
    "def create_dataset():\n",
    "    return [tf.data.Dataset.from_tensor_slices({\n",
    "        'x': tf.random.normal([10, 1]),\n",
    "        'y': tf.random.uniform([1], minval=0, maxval=2, dtype=tf.int32)\n",
    "    }).batch(2) for _ in range(10)]\n",
    "\n",
    "# Define the TFF learning algorithm\n",
    "fed_avg = tff.learning.build_federated_averaging_process(\n",
    "    model_fn=create_model,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.1))\n",
    "\n",
    "# Define the TFF simulation configuration\n",
    "iterative_process = fed_avg.initialize()\n",
    "for round_num in range(10):\n",
    "    sampled_clients = tff.simulation.select_random_clients(\n",
    "        create_dataset(), num_clients=2)\n",
    "    federated_dataset = [create_dataset()[i] for i in sampled_clients]\n",
    "    iterative_process = fed_avg.next(iterative_process, federated_dataset)\n",
    "    train_metrics = tff.learning.metrics.federated_mean(\n",
    "        iterative_process.next_state.metrics['train'])\n",
    "    print(f'Round {round_num}: {train_metrics}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Round 0: {binary_accuracy: 0.485, loss: 0.698}\n",
      "       Round 1: {binary_accuracy: 0.515, loss: 0.694}\n",
      "       Round 2: {binary_accuracy: 0.535, loss: 0.689}\n",
      "       Round 3: {binary_accuracy: 0.485, loss: 0.688}\n",
      "       Round 4: {binary_accuracy: 0.555, loss: 0.684}\n",
      "       Round 5: {binary_accuracy: 0.535, loss: 0.677}\n",
      "       Round 6: {binary_accuracy: 0.555, loss: 0.673}\n",
      "       Round 7: {binary_accuracy: 0.575, loss: 0.665}\n",
      "       Round 8: {binary_accuracy: 0.59, loss: 0.659}\n",
      "       Round 9: {binary_accuracy: 0.575, loss: 0.653}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNMp3gv26NSG"
   },
   "source": [
    "# re-Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a38_inUN7lNU"
   },
   "source": [
    "## Parameters Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1625208957636,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "XAsJUgfC5IuY"
   },
   "outputs": [],
   "source": [
    "num_clients = 9      # Number of clients\n",
    "num_selected = 3     # Typically, num_selected is around 30–40% of the num_clients.\n",
    "batch_size = 128\n",
    "baseline_num = 1000  # choose some data from the train set to retrain the data from trained model \n",
    "num_rounds = 3#100      # Total number of communication rounds for the global model to train.\n",
    "epochs = 5          # for train client model\n",
    "retrain_epochs = 5  # Total number of retraining rounds on the global server after receiving the model weights \n",
    "                      # from all the clients that participated in the communication round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGd3ym1F7gck"
   },
   "source": [
    "## Retraining Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1625208957637,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "-LMi9W6Q5Iq-"
   },
   "outputs": [],
   "source": [
    "\n",
    "def baseline_data(size = baseline_num, batch_size = batch_size): # baseline_num\n",
    "    rng = np.random.default_rng()\n",
    "    x_1 = rng.choice(benign_train_1, size=size, replace = True, shuffle = True, axis=0) # [[[[[[randomly select]]]]]] \n",
    "    x_2 = rng.choice(benign_train_2, size=size, replace = True, shuffle = True, axis=0)\n",
    "    x_3 = rng.choice(benign_train_3, size=size, replace = True, shuffle = True, axis=0)\n",
    "    x_4 = rng.choice(benign_train_4, size=size, replace = True, shuffle = True, axis=0)\n",
    "    x_5 = rng.choice(benign_train_5, size=size, replace = True, shuffle = True, axis=0)\n",
    "    x_6 = rng.choice(benign_train_6, size=size, replace = True, shuffle = True, axis=0)\n",
    "    x_7 = rng.choice(benign_train_7, size=size, replace = True, shuffle = True, axis=0)\n",
    "    x_8 = rng.choice(benign_train_8, size=size, replace = True, shuffle = True, axis=0)\n",
    "    x_9 = rng.choice(benign_train_9, size=size, replace = True, shuffle = True, axis=0)\n",
    "\n",
    "\n",
    "    loader_1 = torch.utils.data.DataLoader(x_1, batch_size=batch_size)\n",
    "    loader_2 = torch.utils.data.DataLoader(x_2, batch_size=batch_size)\n",
    "    loader_3 = torch.utils.data.DataLoader(x_3, batch_size=batch_size)\n",
    "    loader_4 = torch.utils.data.DataLoader(x_4, batch_size=batch_size)\n",
    "    loader_5 = torch.utils.data.DataLoader(x_5, batch_size=batch_size)\n",
    "    loader_6 = torch.utils.data.DataLoader(x_6, batch_size=batch_size)\n",
    "    loader_7 = torch.utils.data.DataLoader(x_7, batch_size=batch_size)\n",
    "    loader_8 = torch.utils.data.DataLoader(x_8, batch_size=batch_size)\n",
    "    loader_9 = torch.utils.data.DataLoader(x_9, batch_size=batch_size)\n",
    "\n",
    "    loaders = {'D1': loader_1,\n",
    "               'D2': loader_2,\n",
    "               'D3': loader_3,\n",
    "               'D4': loader_4,\n",
    "               'D5': loader_5,\n",
    "               'D6': loader_6,\n",
    "               'D7': loader_7,\n",
    "               'D8': loader_8,\n",
    "               'D9': loader_9}\n",
    "\n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF4N6pX57Bmo"
   },
   "source": [
    "## FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1625208957637,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "GEhJPuT5633Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "# FedAvg\n",
    "def server_aggregate(global_model, client_models, client_lens):\n",
    "    total = sum(client_lens)\n",
    "    n = len(client_models)\n",
    "    # n = num_selected\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys(): # calculate average weight/bias --> avg_w/b\n",
    "        global_dict[k] -= torch.stack([client_models[i].state_dict()[k].float() * \n",
    "                                       (n * client_lens[i] / total) for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict()) # local model get updated weight/bias\n",
    "\n",
    "# FedAvgM\n",
    "def server_aggregate_M(global_model, client_models, client_lens):\n",
    "    total = sum(client_lens)    # 592    sum [51, 122, 162, 257]\n",
    "    n = len(client_models)      # 4 local clients\n",
    "    global_dict = global_model.state_dict()\n",
    "    temp = copy.deepcopy(global_dict)     \n",
    "    v = {x:1 for x in copy.deepcopy(global_dict)}   \n",
    "\n",
    "    for i,k in enumerate(global_dict.keys()): \n",
    "        # calculate average weight/bias --> avg_w/b\n",
    "        temp[k] = torch.stack([client_models[i].state_dict()[k].float() * (n * client_lens[i] / total) \n",
    "                               for i in range(len(client_models))], 0).mean(0)\n",
    "       temp_v = 0.9 * v[k] + temp[k]               # v = 0.9v + avg_w/b   momentum=0.9\n",
    "        global_dict[k] = global_dict[k] - temp_v    # w = w - v\n",
    "    global_model.load_state_dict(global_dict)\n",
    "\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict()) # local model get updated weight/bias\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ3RxUY37MjK"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1625208957638,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "VNriwNbu5Imo"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_data_loaders(batch_size = batch_size):\n",
    "    data_1 = torch.utils.data.DataLoader(benign_train_1, batch_size = batch_size, shuffle=True)\n",
    "    data_2 = torch.utils.data.DataLoader(benign_train_2, batch_size = batch_size, shuffle=True)\n",
    "    data_3 = torch.utils.data.DataLoader(benign_train_3, batch_size = batch_size, shuffle=True)\n",
    "    data_4 = torch.utils.data.DataLoader(benign_train_4, batch_size = batch_size, shuffle=True)\n",
    "    data_5 = torch.utils.data.DataLoader(benign_train_5, batch_size = batch_size, shuffle=True)\n",
    "    data_6 = torch.utils.data.DataLoader(benign_train_6, batch_size = batch_size, shuffle=True)\n",
    "    data_7 = torch.utils.data.DataLoader(benign_train_7, batch_size = batch_size, shuffle=True)\n",
    "    data_8 = torch.utils.data.DataLoader(benign_train_8, batch_size = batch_size, shuffle=True)\n",
    "    data_9 = torch.utils.data.DataLoader(benign_train_9, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "    client_loaders = {'D1': data_1,\n",
    "                      'D2': data_2,\n",
    "                      'D3': data_3,\n",
    "                      'D4': data_4,\n",
    "                      'D5': data_5,\n",
    "                      'D6': data_6,\n",
    "                      'D7': data_7,\n",
    "                      'D8': data_8,\n",
    "                      'D9': data_9}\n",
    "\n",
    "    return client_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1625208957639,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "iqaFf_cS5Ifg"
   },
   "outputs": [],
   "source": [
    "\n",
    "def client_update(client_model, optimizer, train_data, epoch=3):\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        running_loss = 0.0\n",
    "        for bx, (data) in enumerate(train_data):\n",
    "            output = client_model(data.float()) # tensor 115\n",
    "            optimizer.zero_grad()\n",
    "            # criterion = nn.MSELoss(reduction='mean')\n",
    "            # loss = criterion(data.to(device), output)\n",
    "            loss = nn.MSELoss(reduction='mean')(data.float().to(device), output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(loss.item())\n",
    "            running_loss += loss.item()\n",
    "        # print(running_loss)\n",
    "        epoch_loss = running_loss/len(train_data)\n",
    "        # metrics['train_loss'].append(epoch_loss)\n",
    "    return epoch_loss\n",
    "    # return loss.item()\n",
    "\n",
    "\n",
    "\n",
    "# synchronizes the client model with global weights (before training)\n",
    "\n",
    "def client_syn(client_model, global_model):\n",
    "    client_model.load_state_dict(global_model.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPE5Fx5I7HZM"
   },
   "source": [
    "## Deep Auto-encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1625208957639,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "QkVroa1V5IjN"
   },
   "outputs": [],
   "source": [
    "# Deep Auto-encoder model\n",
    "\n",
    "input_dim = 115\n",
    "class AEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEModel,self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, int(0.75*input_dim)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(0.75*input_dim), int(0.5*input_dim)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(0.5*input_dim), int(0.33*input_dim)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(0.33*input_dim), int(0.25*input_dim)),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(int(0.25*input_dim), int(0.33*input_dim)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(0.33*input_dim), int(0.5*input_dim)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(0.5*input_dim), int(0.75*input_dim)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(0.75*input_dim), int(input_dim)),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encode = self.encoder(x)\n",
    "        decoder = self.decoder(encode)\n",
    "        return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAX3Z0BI8JDQ"
   },
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1625208957640,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "ZDbfUGGW63zk"
   },
   "outputs": [],
   "source": [
    "global_model = AEModel().to(device)\n",
    "client_models = [AEModel().to(device) for _ in range(num_selected)] # part or all clients\n",
    "\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "opt = [torch.optim.SGD(model.parameters(), lr = 0.012, weight_decay=1e-05, momentum=0.9) for model in client_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1625208957640,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "rzw68gpe63xS"
   },
   "outputs": [],
   "source": [
    "baseline_data = baseline_data()\n",
    "train_loader = train_data_loaders() \n",
    "devices = ['D1','D2','D3','D4','D5','D6','D7','D8','D9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuOW_VP89i7j"
   },
   "source": [
    "# Training Federated Model and gauging packet loss due to intrusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25770,
     "status": "ok",
     "timestamp": 1625208983394,
     "user": {
      "displayName": "Jane Zou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiUdm9ehp01myA8qMFEjs9s-aJHKwnep3JuLYR0BQ=s64",
      "userId": "02362905829031895379"
     },
     "user_tz": -600
    },
    "id": "rT-jMXex63t8",
    "outputId": "407d2497-a271-4dcd-b6bd-115c79a5e347",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "round:  1\n",
      "client_idx:  [4 0 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.29s/it]\n",
      "100%|██████████| 3/3 [00:00<00:00,  8.14it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "client_loss:  2.0081909321735356\n",
      "global_loss:  0.5864895520110925\n",
      "\n",
      "round:  2\n",
      "client_idx:  [8 4 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.73s/it]\n",
      "100%|██████████| 3/3 [00:00<00:00,  8.41it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "client_loss:  3.811922938473279\n",
      "global_loss:  1.2162869274616241\n",
      "\n",
      "round:  3\n",
      "client_idx:  [3 4 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:11<00:00,  3.99s/it]\n",
      "100%|██████████| 3/3 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "client_loss:  4.064452917466719\n",
      "global_loss:  1.3702591756979625\n",
      "\n",
      "TIME: 0.4197697639465332mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Client Model and Global Model\n",
    "train_loss_client = []\n",
    "train_loss_global = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for r in range(num_rounds): # total number of rounds\n",
    "\n",
    "    print('\\nround: ', r+1)\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    print('client_idx: ',client_idx)\n",
    "    client_lens = [len(train_loader[devices[idx]]) for idx in client_idx ] \n",
    "\n",
    "    loss = 0\n",
    "    for i in tqdm(range(num_selected)):\n",
    "        client_syn(client_models[i], global_model)\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[devices[client_idx[i]]], epochs)\n",
    "    train_loss_client.append(loss)\n",
    "\n",
    "\n",
    "    loss_retrain = 0\n",
    "    for i in tqdm(range(num_selected)): \n",
    "        loss_retrain += client_update(client_models[i], opt[i], baseline_data[devices[client_idx[i]]], retrain_epochs)\n",
    "    train_loss_global.append(loss_retrain/num_selected)\n",
    "\n",
    "    server_aggregate_M(global_model, client_models, client_lens)\n",
    "\n",
    "    print(\"\\nclient_loss: \", loss)\n",
    "    print('global_loss: ', loss_retrain/num_selected)\n",
    "\n",
    "torch.save(global_model,'global.pt')\n",
    "\n",
    "time_required = time.time() - start_time\n",
    "print('\\nTIME: {}mins'.format(time_required/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# create dataset\n",
    "df = pd.DataFrame ({\n",
    "        'Group':  ['Training Set', 'Validation Set', 'Testing Set', 'Recall', 'F1 Score'],\n",
    "})\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(9,9)\n",
    "ax.barh(y=df.Group, width=df.Value);\n",
    "ax.set_title('Accuracy Chart');\n",
    "for bars in ax.containers:\n",
    "    ax.bar_label(bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Federated Model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
